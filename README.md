## Обоснованность разработки продукта
### Описание проекта: 
Проект создан для улучшения музыкальных рекомендательных систем на стриминговых сервисах путем учета эмоциональных характеристик песен в динамике.

Модель извлекает из треков значения arousal и valence каждую секунду. На выходе модели получаем два вектора arousal и valence, длина которых зависит от выбранной средней продолжительности трека (например, 3 минуты). Полученные характеристики затем подаются в рекомендательные системы для улучшения подбора похожих песен для каждого пользователя.

Модель основана на модели Дж. Рассела, которая оценивает эмоциональное состояние трека на основе двух показателей - arousal и valence.

### NOTION: дополнительная информация
https://voracious-flare-03b.notion.site/Music-emotion-project-5332d3d7e4ca4f3f9d7ff8a8a7ef52a4?pvs=4 

### Бизнес цель
Цель проекта заключается в создание модели, которая кажду секунду извлекает значения arousal и valence для улучшении музыкальных рекомендательных систем для стриминговых сервисов, в обеспечении наилучшего подбора похожих песен для каждого пользователя.

Улучшение: проект учитывает эмоциональные характеристики песен в динамике. На данный момент большинстов рекомендательных систем используют общие показатели для оценки треков, что не всегда позволяет получить максимально точные рекомендации. Для решения этой проблемы была использована модель Дж. Рассела, которая позволит оценить эмоциональное состояние трека на основе двух показателей - arousal и valence. Модель машинного обучения оценивает эти два показателя каждую секунду, что дает более точную картину эмоциональной динамики песен.

### Критерии успеха: 

1) бизнес метрика: average session duratio - метрика измеряет эффективность новой рекомендательной системы, насколько она увеличивает время, проведенное пользователем на платформе. Чем выше average session duration, тем выше вероятность, что пользователи продолжат использовать сервис.

2) ML метрика для рек систем: precision@k - метрика позволяет оценить, насколько точно рекомендательная система рекомендует пользователю песни, которые ему должны понравится. Высокое значение будет сигнализировать о том, что модель действительно учитывает эмоциональную составляющую песни.

$$precision@k (number of relevant recommended k items) / k$$ ,
где k - количество рекомендованных песен

3) Самая важная метрика: ML метрика RMSE (так как стоит задача регерссии) - насколько точно модель оценивает эмоционаьлные характеристики трека. Она позволит оценивать предсказание модели в тех же единицах измерения, что и сиходные данные. Использование метрики RMSE сильнее наказывает за большие оценки и позволяет оценить способность модели предсказывать редкие эмоции.
$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2}$$

4) Для того, чтобы оценить работу модели в общем, была использовала метрика MAE. Она всегда будет меньше RMSE, 
так как не сильно наказывает за некоректное опредление редких музыкальных производений (треков во втором и третьем квадрантах).
$$\text{MAE}(y, \hat{y}) = \frac{ \sum_{i=0}^{N - 1} |y_i - \hat{y}_i| }{N}$$

Чем меньше RMSE и MAE тем выше precision@k, тем выше вероятность того, что пользователю будут рекомендоваться годные треки

### Baseline
Была разработана базовая модель, основанная на resnet18 и мел-спектрограмме, и обучена на DEAM датасете в течение 20 эпох, чтобы проверить ее работоспособность. Затем была построена content-based рекомендательная система, основанная на косинусном сходстве, с использыванием музыкальных признаков, извлеченных при помощи spotipy API, чтобы определить, могут ли вектора (arousal и valence) улучшить работу рекомендательной системы.

Для тестирования эффективности модели использовалось 50 первых плейлистов из датасета Million Playlists Dataset от Spotify. Первоначальная рекомендательная система, основанная на признаках, достигла метрики Precision@10 в 33,75%. Однако, модель была улучшена путем создания дополнительного датафрейма, который включал в себя предыдущие признаки, а также векторы arousal и valence, что привело к увеличению метрики Precision@10 до 35,25%. Было спарено 2700 треков.

Основные две таргетные переменные: arousal и valence 

### MVP
1) Для реализации проекта был проведен дополнительный сбор данных, при котором 
было решено использовать датасет Pmemo. Данный выбор обусловлен тем, что он содержит 
аудиозаписи за 2019 год (в отличие от DEAM 2013-2015) и представляет собой более репрезентативный набор данных. 
Он включает наиболее выразительные композиции, которые порождают либо грустные, либо веселые эмоции, что ближе к реальным плейлистам пользователей.

2) Затем были рассмотрены различные варианты признаков и архитектуры модели. Изучены были полносвязные слои с 
использованием 80 низкоуровневых признаков, полученных с помощью библиотеки OpenSmile, а также Conv2d и mel-спектрограммы,
LSTM и MFCC, MFCC и Conv1d + LSTM. В результате было принято решение использовать архитектуру Conv1d + fc и обучать 
модель на датасете MFCC. Далее работа модели была проверена в рекомендательных системах на исторических данных пользователей, используя метрику precision@k.

3) Было разработано веб-приложение с использованием фреймворка Flask и создан пользовательский интерфейс для его 
демонстрации. Впоследствии компании, занимающиеся разработкой рекомендательных систем, могут воспользоваться 
API для получения оценок эмоций (arousal и valence) и статистических характеристик для каждой
аудиозаписи в стриминговом сервисе. Кроме того, они могут получить текстовое описание общей эмоции музыки при 
помощи модели gpt.

4) Пользовательский интерфейс представляет собой веб-сайт, где пользователи могут просмотреть результаты обработки 
каждой песни на сервере. Они также могут выбрать понравившиеся аудиозаписи и получить рекомендации на основе их 
эмоциональных векторов.

