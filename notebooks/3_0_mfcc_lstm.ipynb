{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrxFLO5uNd6f",
        "outputId": "1df730c1-cc79-4dfd-c68b-64f7c05bad8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3xFVdRAOVYv",
        "outputId": "13fd1705-cb10-4e4a-eb0a-c9f9283ed6d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch\n",
        "!pip install torch==1.13.1"
      ],
      "metadata": {
        "id": "J5emDVvb2ej2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vhDTeOrgIIoc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import multiprocessing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable \n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### создаем датасет: music folder - музфкальные треки длиной в 1 секунду\n",
        "\n",
        "### annotation.csv - содержит id треков, arousal и valence"
      ],
      "metadata": {
        "id": "8-fZo3mRKU6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/PMEmo/annotation.csv', 'w') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerows([['song_id', 'arousal', 'valence']])\n",
        "\n",
        "def save_csv(music, music_name, sr, arousal_sec, valence_sec, counter):\n",
        "  music = music[counter]\n",
        "  sf.write(f'/content/gdrive/MyDrive/PMEmo/music/{music_name}_{counter}.wav', music, sr)\n",
        "  with open('/content/gdrive/MyDrive/PMEmo/annotation.csv', 'a') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows([[f'{music_name}_{counter}', arousal_sec, valence_sec]])\n",
        "\n",
        "def make_dataset(song_dir, annotaion_dir):\n",
        "  df = pd.read_csv(annotaion_dir)\n",
        "  for elem in sorted(os.listdir(song_dir), key=lambda x: int(x[:x.index('.')])):\n",
        "    music, sr = librosa.load(f'{song_dir}/{elem}', mono=True, sr=None)\n",
        "    start_time = librosa.time_to_samples(15, sr=sr)\n",
        "    music = music[start_time:]\n",
        "    music_length = music.shape[0] // sr\n",
        "    if music_length == 0:\n",
        "      continue\n",
        "    frame_duration = 1\n",
        "    frame_length = int(frame_duration * sr)\n",
        "    music = librosa.util.frame(music, frame_length=frame_length, hop_length=frame_length, axis=0)\n",
        "    music_name = int(elem.split('.')[0])\n",
        "\n",
        "    arousal = list(df[df['musicId'] == music_name]['Arousal(mean)'].values)\n",
        "    valence = list(df[df['musicId'] == music_name]['Valence(mean)'].values)\n",
        "\n",
        "    for counter, index in enumerate(range(0, len(arousal), 2)):\n",
        "      if (counter == len(music)) or (index+1 == len(arousal)):\n",
        "        continue\n",
        "      arousal_sec = (arousal[index] + arousal[index+1])/2\n",
        "      valence_sec = (valence[index] + valence[index+1])/2\n",
        "      save_csv(music, music_name, sr, arousal_sec, valence_sec, counter)\n"
      ],
      "metadata": {
        "id": "lKv0f-XpKXEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/gdrive/MyDrive/PMEmo/music'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBiSARoJn0rv",
        "outputId": "88069792-acc4-47c7-a3fb-1f6d42917655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18212"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/gdrive/MyDrive/PMEmo/lstm/mfcc'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg3WQkQ_3XKW",
        "outputId": "53dbeb79-c31b-44ea-f499-829c4800e431"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18212"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создаем dataframe для обучения lstm: извлекаем mfcc, song_id, arousal, valence"
      ],
      "metadata": {
        "id": "ESID8EGc5nMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mfcc_dataset(music_dir):\n",
        "    for song in sorted(os.listdir(music_dir)):\n",
        "        music, sr = librosa.load(os.path.join(music_dir, song), mono=True, sr=None)\n",
        "        features = librosa.feature.mfcc(y=music, sr=sr, n_fft=2048, n_mfcc=30,\n",
        "                                hop_length=512)\n",
        "        music_id = song.split('.')[0]\n",
        "        np.save(f'/content/gdrive/MyDrive/PMEmo/lstm/mfcc/{music_id}.npy', features)\n",
        "        "
      ],
      "metadata": {
        "id": "OHJwpqex5mey"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_dir = '/content/gdrive/MyDrive/PMEmo/music'\n",
        "make_mfcc_dataset(music_dir)"
      ],
      "metadata": {
        "id": "drAoxdum9d-O"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.mfcc_dir = '/content/gdrive/MyDrive/PMEmo/lstm/mfcc'\n",
        "    self.music_name = sorted(os.listdir(self.mfcc_dir))\n",
        "    self.annot_df = pd.read_csv('/content/gdrive/MyDrive/PMEmo/annotation.csv')\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.music_name)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    music = self.music_name[idx]\n",
        "    mfcc = torch.tensor(np.load(os.path.join(self.mfcc_dir, music)).T, dtype=torch.float)\n",
        "    arousal = torch.tensor(self.annot_df[self.annot_df['song_id'] == music.split('.')[0]]['arousal'].values[0], dtype=torch.float)\n",
        "    valence = torch.tensor(self.annot_df[self.annot_df['song_id'] == music.split('.')[0]]['valence'].values[0], dtype=torch.float)\n",
        "    return music.split('.')[0], mfcc, arousal, valence\n"
      ],
      "metadata": {
        "id": "prpVOPh6IPtR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MusicDataset()"
      ],
      "metadata": {
        "id": "WFNObxmYQkHH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(dataset) * 0.8)\n",
        "valid_size = len(dataset) - train_size\n",
        "print(train_size)\n",
        "print(valid_size)"
      ],
      "metadata": {
        "id": "Big6ePU9RbW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c3ce09-8206-4ff8-f5e8-e34d40b772be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14569\n",
            "3643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "valid_data = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "mmO33eR5Rc-P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_name, music, arousal, valence = next(iter(train_data))\n",
        "music.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x24Q8RDORfaE",
        "outputId": "c97367d7-74f5-4ad6-ba75-62cd98de870a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 87, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arousal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrhQrQefy_Vm",
        "outputId": "59c26891-e243-4b45-8add-9de94224f2b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "VeJg4OjyUkse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, seq_length, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.seq_length = seq_length\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(32)\n",
        "        self.fc1 = nn.Sequential(nn.Linear(self.hidden_size, 32),\n",
        "                                 self.batch_norm1,\n",
        "                                 nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(32, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
        "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
        "        output, (hidden_layer, _) = self.lstm(x.to(self.device), (h_0.to(self.device), c_0.to(self.device)))\n",
        "        out_fc1 = self.fc1(hidden_layer[-1])\n",
        "        out = self.fc2(out_fc1)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "vnejhokenG1E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woCjPHtNV8TZ",
        "outputId": "e4f3fd40-03fe-4cf1-a5e9-40df5822fb87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(20, 64, 1, 87, device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "_67iJFXRV3QB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modle = model.to(device)\n",
        "model(music.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnbkpooP5gL",
        "outputId": "1ab4dc58-eeed-4c7d-f031-8d735c08e962"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение"
      ],
      "metadata": {
        "id": "BQq83qLtWKit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/PMEmo/lstm/history.csv', 'w') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerows([['epoch', 'train_loss', 'valid_loss']])"
      ],
      "metadata": {
        "id": "d3_DIcM-lzKa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I2a0iFJEcKOz"
      },
      "outputs": [],
      "source": [
        "def train_model(model, n_epochs, optimizer, criterion, target):\n",
        "    model.to(device)\n",
        "    \n",
        "    history = {\n",
        "    'train_losses': [],\n",
        "    'valid_losses': []\n",
        "    }\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        train_losses_iter = []\n",
        "        model.train()\n",
        "        j=0\n",
        "        for _, music, arousal, valence in train_data:\n",
        "            if j % 10 == 0:\n",
        "              print(f'{j} итерация в train')\n",
        "            j+=1\n",
        "            music, arousal, valence = music.to(device), arousal.to(device), valence.to(device)\n",
        "            out = model(music)\n",
        "            if target == 'arousal':\n",
        "              loss = torch.sqrt(criterion(out.float().squeeze(), arousal.float()))\n",
        "            elif target == 'valence':\n",
        "              loss = torch.sqrt(criterion(out.float().squeeze(), valence.float()))\n",
        "            train_losses_iter.append(loss.item())\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        history['train_losses'].append(np.mean(train_losses_iter))\n",
        "\n",
        "        valid_losses_iter = []\n",
        "        model.eval()\n",
        "\n",
        "        i=0\n",
        "        for _, music, arousal, valence in valid_data:\n",
        "          i+= 1\n",
        "          if i % 10 == 0:\n",
        "            print(f'{i} итерация в valid')\n",
        "    \n",
        "          music, arousal, valence = music.to(device), arousal.to(device), valence.to(device)\n",
        "          out = model(music)\n",
        "          if target == 'arousal':\n",
        "            loss = torch.sqrt(criterion(out.float().squeeze(), arousal.float()))\n",
        "          elif target == 'valence':\n",
        "            loss = torch.sqrt(criterion(out.float().squeeze(), valence.float()))\n",
        "          valid_losses_iter.append(loss.item())\n",
        "\n",
        "        history['valid_losses'].append(np.mean(valid_losses_iter))\n",
        "\n",
        "        with open('/content/gdrive/MyDrive/PMEmo/lstm/history.csv', 'a') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerows([[epoch, round(history[\"train_losses\"][-1], 4), round(history[\"valid_losses\"][-1], 4)]])\n",
        "  \n",
        "        torch.save(model.state_dict(), '/content/gdrive/MyDrive/PMEmo/lstm/weights/each_epochs.pt')\n",
        "        if epoch == 100:\n",
        "          torch.save(model.state_dict(), '/content/gdrive/MyDrive/PMEmo/lstm/weights/100_epochs.pt')\n",
        "        if epoch == 199:\n",
        "          torch.save(model.state_dict(), '/content/gdrive/MyDrive/PMEmo/lstm/weights/200_epochs.pt')\n",
        "        print(f'train: accuracy {history[\"train_losses\"][-1]:.4f}\\n'\n",
        "        f'valid:  accuracy {history[\"valid_losses\"][-1]:.4f}')\n",
        "        print(f'{\"-\"*35}')\n",
        "        print() \n",
        "    return history      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hystory = train_model(model, 200, optimizer, criterion, 'arousal')"
      ],
      "metadata": {
        "id": "gVKxeTAkX_EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7S6m7W9ttYKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}